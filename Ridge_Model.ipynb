{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e1c4153-8031-44f2-abcb-a4abc52b7821",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Code produced by Ayden McCarthy\n",
    "# Manuscript Title: \"Machine Learning Models Predict Assessment Outcomes \n",
    "#                    From Military Physical Employment Standards Via a \n",
    "#                    Physical Test Battery\"\n",
    "# Program of Study: PhD Candidacy\n",
    "# Institution: Macquarie University\n",
    "# Year: 2024\n",
    "######################################################################\n",
    "\n",
    "######################################################################\n",
    "# Note for Users:\n",
    "# This code is intended for use within Python JupyterLab.\n",
    "# It requires data to be set up according to the instructions \n",
    "# outlined in the manuscript. Users can follow the code comments to \n",
    "# understand each step of the analysis.\n",
    "# Please ensure that you replace the placeholder CSV file names in \n",
    "# the code with the names of your specific data files to run the code \n",
    "# successfully.\n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292f5cbd-92e7-45d7-94e8-8b08f1b31ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules for all machine learning models produced in the manuscript, not just the ridge, which is useful for installing these in general.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import time\n",
    "from itertools import combinations\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV, RidgeCV, ElasticNetCV, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb992670-f075-4772-8df1-a42a5927e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HTML for text with black color\n",
    "html_text = \"\"\"\n",
    "<div style='font-size:70px; font-weight:bold; text-align:center; color: black;'>\n",
    "    Ridge Regression Model\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML in the output cell\n",
    "HTML(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca0fc3-2052-453a-b9bf-cd89065940b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('Training_Set_Reduced_with_Important_Features.csv') ###Please change to your own dataset.\n",
    "\n",
    "# Separate features (predictors) and target variable\n",
    "X = df.drop(columns=['Weight Lifted (Kg)']) ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "y = df['Weight Lifted (Kg)'] ######## Outcome variable\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define hyperparameter grid for Ridge model\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-8, 8, 200)\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV for Ridge model\n",
    "ridge_search = GridSearchCV(Ridge(), param_grid, cv=LeaveOneOut(), scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "ridge_search.fit(X_scaled, y)\n",
    "\n",
    "# Extract the best Ridge model from GridSearchCV\n",
    "best_ridge = ridge_search.best_estimator_\n",
    "\n",
    "# Initialize RFECV for feature selection with Ridge model\n",
    "rfecv = RFECV(estimator=best_ridge, step=1, cv=LeaveOneOut(), scoring='neg_mean_squared_error')\n",
    "rfecv.fit(X_scaled, y)\n",
    "\n",
    "# Number of features selected by RFECV\n",
    "n_features = rfecv.n_features_\n",
    "selected_features = X.columns[rfecv.support_]\n",
    "X_selected = X_scaled[:, rfecv.support_]\n",
    "\n",
    "print(f\"Number of features selected by Ridge model: {n_features}\")\n",
    "\n",
    "# Fit Ridge model with the features selected by RFECV\n",
    "best_ridge.fit(X_selected, y)\n",
    "\n",
    "# Calculate RMSE for the Ridge model using the selected features\n",
    "mse_scores = cross_val_score(best_ridge, X_selected, y, scoring='neg_mean_squared_error', cv=LeaveOneOut())\n",
    "rmse_optimal = np.sqrt(-mse_scores.mean())\n",
    "print(f\"RMSE using optimal {n_features} features in Ridge model: {rmse_optimal}\")\n",
    "\n",
    "# Initialize SHAP Explainer for model interpretation\n",
    "explainer = shap.Explainer(best_ridge.predict, shap.sample(X_selected, 100))\n",
    "\n",
    "# Calculate SHAP values for the selected features\n",
    "shap_values = explainer(X_selected)\n",
    "shap.summary_plot(shap_values, X_selected, feature_names=selected_features)\n",
    "\n",
    "# Calculate mean absolute SHAP values to determine feature importance\n",
    "shap_sum = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding SHAP values\n",
    "feature_importance = pd.DataFrame(list(zip(selected_features, shap_sum)), columns=['Feature', 'SHAP Value'])\n",
    "feature_importance = feature_importance.sort_values(by='SHAP Value', ascending=False)\n",
    "\n",
    "print(\"Feature Importance based on SHAP values:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Store results in a dictionary\n",
    "LOO_model_results = {\n",
    "    'Ridge': {\n",
    "        'RMSE Optimal': rmse_optimal,\n",
    "        'Optimal Features': selected_features,\n",
    "        'RFECV Support': rfecv.support_,\n",
    "        'Model': best_ridge,\n",
    "        'Feature Importance': feature_importance\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Analysis Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8787b8e4-a70c-446a-9a06-ce469a441919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HTML for text with black color\n",
    "html_text = \"\"\"\n",
    "<div style='font-size:60px; font-weight:bold; text-align:center; color: black;'>\n",
    "    Save optimal features as a .csv file\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML in the output cell\n",
    "HTML(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e21ddf-3b2d-4e5f-8199-a713f88dd97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming LOO_model_results is a dictionary where each key is a model name,\n",
    "# and each value is a dictionary containing model info, including 'Optimal Features'\n",
    "for model_name, model_info in LOO_model_results.items():\n",
    "    # Extract the selected features - Check if 'Optimal Features' exists in the dictionary to avoid KeyError\n",
    "    if 'Optimal Features' in model_info:\n",
    "        selected_features = model_info['Optimal Features']\n",
    "    else:\n",
    "        print(f\"No 'Optimal Features' found for {model_name}.\")\n",
    "        continue\n",
    "\n",
    "    # Add 'Weight Lifted (Kg)' to the list of features\n",
    "    # Ensure that 'Weight Lifted (Kg)' is not already in the list to avoid duplication\n",
    "    if 'Weight Lifted (Kg)' not in selected_features: ############ Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "        selected_features_with_target = list(selected_features) + ['Weight Lifted (Kg)'] ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "    else:\n",
    "        selected_features_with_target = list(selected_features)\n",
    "\n",
    "    # Filter the original DataFrame based on these features\n",
    "    # Ensure the features exist in the DataFrame to avoid KeyError\n",
    "    missing_features = [feature for feature in selected_features_with_target if feature not in df.columns]\n",
    "    if missing_features:\n",
    "        print(f\"The following features are missing in the DataFrame for {model_name}: {missing_features}\")\n",
    "        continue\n",
    "    df_filtered = df[selected_features_with_target]\n",
    "\n",
    "    # Save the filtered data to a CSV file\n",
    "    # Using a safe string for the filename (replacing spaces and slashes)\n",
    "    safe_model_name = model_name.replace(' ', '_').replace('/', '_')\n",
    "    filename = f'{safe_model_name}_optimal_features_data_LOO.csv'\n",
    "    df_filtered.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Saved data for {model_name} with optimal features to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae344ff-97ca-418c-a998-478ec619b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HTML for text with black color\n",
    "html_text = \"\"\"\n",
    "<div style='font-size:60px; font-weight:bold; text-align:center; color: black;'>\n",
    "    Optimised Ridge Parameters\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML in the output cell\n",
    "HTML(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b95d5-de16-40cf-8428-74deaa3e7fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_ridge = pd.read_csv('Ridge_optimal_features_data_LOO.csv')  \n",
    "\n",
    "# Separate features and target variable\n",
    "X = df_ridge.drop(['Weight Lifted (Kg)'], axis=1)  ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "y = df_ridge['Weight Lifted (Kg)'] ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "\n",
    "# Standardise the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Define a range of alpha values to explore\n",
    "alphas = np.logspace(-10, 10, 200)  # Wide range of alpha values\n",
    "\n",
    "# Initialise RidgeCV with Leave-One-Out Cross-Validation\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=LeaveOneOut(), scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit RidgeCV on the data\n",
    "ridge_cv.fit(X_scaled, y)\n",
    "\n",
    "# Find the best alpha value\n",
    "best_alpha = ridge_cv.alpha_\n",
    "print(\"Best alpha for Ridge:\", best_alpha)\n",
    "\n",
    "# Train the Ridge model with the best alpha\n",
    "ridge_best = Ridge(alpha=best_alpha)\n",
    "ridge_best.fit(X_scaled, y)\n",
    "\n",
    "# Make predictions and calculate RMSE\n",
    "y_pred = ridge_best.predict(X_scaled)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "print(\"Root Mean Squared Error for Ridge:\", rmse)\n",
    "\n",
    "# Plot a histogram of the residuals\n",
    "residuals = y - y_pred\n",
    "plt.hist(residuals, bins=30, edgecolor='black')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals for Ridge LOO')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6525ab55-6925-4ac9-a66c-8707e26bba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HTML for text with black color\n",
    "html_text = \"\"\"\n",
    "<div style='font-size:60px; font-weight:bold; text-align:center; color: black;'>\n",
    "    Testing Set - Unseen Data\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML in the output cell\n",
    "HTML(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ebb3a1-ac1b-426a-aa67-b55767cc3e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing dataset\n",
    "df_testing = pd.read_csv('Testing_Set.csv') ###Please change to your own dataset.\n",
    "\n",
    "# Encoding 'Sex' column\n",
    "#df_testing['Sex'] = df_testing['Sex'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Select the same columns as in the training dataset\n",
    "X_testing = df_testing[X.columns]\n",
    "\n",
    "# Standardize the features in the testing dataset using the same scaler used for the training data\n",
    "X_testing_scaled = scaler.transform(X_testing)\n",
    "\n",
    "# Use the trained Ridge model to make predictions on the testing dataset\n",
    "y_pred_testing = ridge_best.predict(X_testing_scaled)\n",
    "\n",
    "# Add the predicted values to the testing dataset\n",
    "df_testing['Predicted_Weight_Lifted'] = y_pred_testing\n",
    "\n",
    "# Calculate RMSE for testing data (if true target values are available)\n",
    "true_y_testing = df_testing['Weight Lifted (Kg)'] ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "rmse_testing = np.sqrt(mean_squared_error(true_y_testing, y_pred_testing))\n",
    "print(\"Root Mean Squared Error on Testing Data (Ridge):\", rmse_testing)\n",
    "\n",
    "# Plot the true vs. predicted values with improved styling\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot for the predicted values\n",
    "plt.scatter(true_y_testing, y_pred_testing, alpha=0.7, label='Predicted', color='blue', edgecolors='w')\n",
    "\n",
    "# Scatter plot for the true values\n",
    "plt.scatter(true_y_testing, true_y_testing, alpha=0.7, label='True', color='red', edgecolors='w')\n",
    "\n",
    "# Diagonal line indicating perfect predictions\n",
    "plt.plot([true_y_testing.min(), true_y_testing.max()], [true_y_testing.min(), true_y_testing.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "\n",
    "# Styling the plot\n",
    "plt.style.use('ggplot')  # Using ggplot style for more appealing visuals\n",
    "plt.xlabel('True Weight Lifted (Kg)', fontsize=14)\n",
    "plt.ylabel('Predicted Weight Lifted (Kg)', fontsize=14)\n",
    "plt.title('Ridge LOO True vs. Predicted Weight Lifted (Testing Data)', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the predictions and the plot to files\n",
    "df_testing.to_csv('Testing_Set_Predictions_Ridge_LOO_RFE.csv', index=False)\n",
    "plt.savefig('True_vs_Predicted_Plot_Ridge_LOO.png', format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3d05d-75f3-4c4a-b70d-fa7564458242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
