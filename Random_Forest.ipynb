{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2238870-5d96-4b38-9fe5-00b6969d4b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Code produced by Ayden McCarthy\n",
    "# Manuscript Title: \"Machine Learning Models Predict Assessment Outcomes \n",
    "#                    From Military Physical Employment Standards Via a \n",
    "#                    Physical Test Battery\"\n",
    "# Program of Study: PhD Candidacy\n",
    "# Institution: Macquarie University\n",
    "# Year: 2024\n",
    "######################################################################\n",
    "\n",
    "######################################################################\n",
    "# Note for Users:\n",
    "# This code is intended for use within Python JupyterLab.\n",
    "# It requires data to be set up according to the instructions \n",
    "# outlined in the manuscript. Users can follow the code comments to \n",
    "# understand each step of the analysis.\n",
    "# Please ensure that you replace the placeholder CSV file names in \n",
    "# the code with the names of your specific data files to run the code \n",
    "# successfully.\n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8c349c-f9f6-4375-b69f-e2e39deef86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules for all machine learning models produced in the manuscript\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import time\n",
    "from itertools import combinations\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LassoCV, RidgeCV, ElasticNetCV, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut, KFold, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e4776-3794-4c48-b986-964b5ff265a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HTML for text with black color\n",
    "html_text = \"\"\"\n",
    "<div style='font-size:70px; font-weight:bold; text-align:center; color: black;'>\n",
    "    Random Forest Model\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML in the output cell\n",
    "HTML(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637bd3fd-e1e9-45be-a12f-617c778ccbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Note: The below can take some time and compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae11fba-74eb-47c9-9185-17ce569b1826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('Training_Set_Reduced_with_Important_Features.csv') ###Please change to your own dataset.\n",
    "\n",
    "# Separate features (predictors) and target variable\n",
    "X = df.drop(columns=['Weight Lifted (Kg)']) ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "y = df['Weight Lifted (Kg)'] ######## Outcome variable\n",
    "\n",
    "# Define parameter grid for Random Forest model\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4, 6]\n",
    "}\n",
    "\n",
    "# Perform Grid Search CV for hyperparameter tuning for Random Forest\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf, cv=LeaveOneOut(), scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search_rf.fit(X, y)\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "# Initialize the Random Forest model with the best hyperparameters\n",
    "best_rf = RandomForestRegressor(**best_params_rf, random_state=42)\n",
    "\n",
    "# Initialize RFECV for feature selection with the optimized Random Forest model\n",
    "rfecv = RFECV(estimator=best_rf, step=1, cv=LeaveOneOut(), scoring='neg_mean_squared_error')\n",
    "rfecv.fit(X, y)\n",
    "\n",
    "# Number of features selected by RFECV\n",
    "n_features = rfecv.n_features_\n",
    "selected_features = X.columns[rfecv.support_]\n",
    "X_selected = X[selected_features]\n",
    "\n",
    "print(f\"Number of features selected by Random Forest: {n_features}\")\n",
    "\n",
    "# Fit the Random Forest model with the selected features\n",
    "best_rf.fit(X_selected, y)\n",
    "\n",
    "# Calculate RMSE using the optimal number of features\n",
    "mse_scores = rfecv.cv_results_['mean_test_score']\n",
    "rmse_optimal = np.sqrt(-mse_scores.max())\n",
    "print(f\"RMSE using optimal {n_features} features in Random Forest: {rmse_optimal}\")\n",
    "\n",
    "# Initialize SHAP Explainer to interpret model predictions\n",
    "explainer = shap.Explainer(best_rf.predict, shap.sample(X_selected, 100))\n",
    "\n",
    "# Calculate SHAP values for the selected features\n",
    "shap_values = explainer(X_selected)\n",
    "shap.summary_plot(shap_values, X_selected, feature_names=selected_features)\n",
    "\n",
    "# Calculate the mean absolute SHAP values for feature importance\n",
    "shap_sum = np.abs(shap_values.values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame with feature names and their corresponding SHAP values\n",
    "feature_importance = pd.DataFrame(list(zip(selected_features, shap_sum)), columns=['Feature', 'SHAP Value'])\n",
    "feature_importance = feature_importance.sort_values(by='SHAP Value', ascending=False)\n",
    "\n",
    "print(\"Feature Importance based on SHAP values:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Store results in a dictionary\n",
    "LOO_RF_model_results = {\n",
    "    'Random Forest': {\n",
    "        'Best Parameters': best_rf.get_params(),\n",
    "        'RMSE Optimal': rmse_optimal,\n",
    "        'Optimal Features': selected_features,\n",
    "        'RFECV Support': rfecv.support_,\n",
    "        'Model': best_rf,\n",
    "        'Feature Importance': feature_importance\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Analysis Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714f822-0340-4351-a3ae-070643d357cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model results and optimal features\n",
    "for model_name, model_info in LOO_RF_model_results.items():\n",
    "    # Extract the selected features - Check if 'Optimal Features' exists in the dictionary to avoid KeyError\n",
    "    if 'Optimal Features' in model_info:\n",
    "        selected_features = model_info['Optimal Features']\n",
    "    else:\n",
    "        print(f\"No 'Optimal Features' found for {model_name}.\")\n",
    "        continue\n",
    "\n",
    "    # Add 'Weight Lifted (Kg)' to the list of features\n",
    "    # Ensure that 'Weight Lifted (Kg)' is not already in the list to avoid duplication\n",
    "    if 'Weight Lifted (Kg)' not in selected_features: ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "        selected_features_with_target = list(selected_features) + ['Weight Lifted (Kg)'] ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "    else:\n",
    "        selected_features_with_target = list(selected_features)\n",
    "\n",
    "    # Filter the original DataFrame based on these features\n",
    "    # Ensure the features exist in the DataFrame to avoid KeyError\n",
    "    missing_features = [feature for feature in selected_features_with_target if feature not in df.columns]\n",
    "    if missing_features:\n",
    "        print(f\"The following features are missing in the DataFrame for {model_name}: {missing_features}\")\n",
    "        continue\n",
    "    df_filtered = df[selected_features_with_target]\n",
    "\n",
    "    # Save the filtered data to a CSV file\n",
    "    # Using a safe string for the filename (replacing spaces and slashes)\n",
    "    safe_model_name = model_name.replace(' ', '_').replace('/', '_')\n",
    "    filename_filtered = f'{safe_model_name}_optimal_features_data_LOO.csv'\n",
    "    df_filtered.to_csv(filename_filtered, index=False)\n",
    "\n",
    "    # Save the model results (including feature importance and RMSE) to a CSV file\n",
    "    filename_results = f'{safe_model_name}_model_results_LOO.csv'\n",
    "    model_info['Feature Importance'].to_csv(filename_results, index=False)\n",
    "\n",
    "    print(f\"Saved data for {model_name} with optimal features to {filename_filtered}\")\n",
    "    print(f\"Saved model results for {model_name} to {filename_results}\")\n",
    "\n",
    "print(\"Data saving process complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf45f4-f478-4e51-a0a7-e2b95f3cc111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HTML for text with black color\n",
    "html_text = \"\"\"\n",
    "<div style='font-size:70px; font-weight:bold; text-align:center; color: black;'>\n",
    "    Optimised Models Paramters\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML in the output cell\n",
    "HTML(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80617ac7-6c9e-424e-89a6-06f93db8af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note: This script takes singificant time and compute resources. Adjust the parameters as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb6476-561a-4564-9f28-a83cd8352482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df_rf = pd.read_csv('Random_Forest_optimal_features_data_LOO.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df_rf.drop(['Weight Lifted (Kg)'], axis=1) ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "y = df_rf['Weight Lifted (Kg)'] ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "\n",
    "# Define a more extensive parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],  # Adding more options for the number of trees\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],  # Expanding the range for the maximum depth of trees\n",
    "    'min_samples_split': [2, 4, 6, 8, 10],  # Expanding the range for the minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5],  # Expanding the range for the minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Adding options for the number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False]  # Adding options for bootstrap samples\n",
    "}\n",
    "\n",
    "# Initialise models\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialise Leave-One-Out cross-validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Perform Grid Search CV for hyperparameter tuning\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=loo, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "print(\"*** Tuning hyperparameters for Random Forest... ***\")\n",
    "grid_search_rf.fit(X, y)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best parameters found:\", best_params_rf)\n",
    "\n",
    "# Train the Random Forest model with the best hyperparameters\n",
    "rf_best = RandomForestRegressor(**best_params_rf, random_state=42)\n",
    "rf_best.fit(X, y)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_loo_rf = rf_best.predict(X)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse_loo_rf = np.sqrt(mean_squared_error(y, y_pred_loo_rf))\n",
    "print(\"Root Mean Squared Error (LOO):\", rmse_loo_rf)\n",
    "\n",
    "# Calculate residuals\n",
    "residuals_loo_rf = y - y_pred_loo_rf\n",
    "\n",
    "# Plot a histogram of the residuals\n",
    "plt.hist(residuals_loo_rf, bins=30, edgecolor='black')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Residuals Random Forest LOO')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c0e3b-d936-4d3e-b2cd-7548fb10318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HTML for text with black color\n",
    "html_text = \"\"\"\n",
    "<div style='font-size:70px; font-weight:bold; text-align:center; color: black;'>\n",
    "    Testing Phase On Unseen Data\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# Display the HTML in the output cell\n",
    "HTML(html_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e46a50c-cf61-435a-a7a4-469778554d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing dataset\n",
    "df_testing = pd.read_csv('Testing_Set.csv') ###Please change to your own dataset.\n",
    "\n",
    "# Encoding 'Sex' column (if applicable)\n",
    "#df_testing['Sex'] = df_testing['Sex'].map({'M': 0, 'F': 1})\n",
    "\n",
    "# Select the same columns as in the training dataset\n",
    "X_testing = df_testing[X.columns]  # Use the features selected from LOO RF model\n",
    "\n",
    "# Use the trained Random Forest model to make predictions on the testing dataset\n",
    "y_pred_testing_rf = rf_best.predict(X_testing)\n",
    "\n",
    "# Add the predicted values to the testing dataset\n",
    "df_testing['Predicted_Weight_Lifted_RF'] = y_pred_testing_rf\n",
    "\n",
    "# Calculate RMSE for testing data (if true target values are available)\n",
    "true_y_testing = df_testing['Weight Lifted (Kg)'] ######## Your outcome variable is to be placed where 'Weight Lifted (Kg)' is. This was the lift-to-place results.\n",
    "rmse_testing_rf = np.sqrt(mean_squared_error(true_y_testing, y_pred_testing_rf))\n",
    "print(\"Root Mean Squared Error on Testing Data (Random Forest LOO):\", rmse_testing_rf)\n",
    "\n",
    "# Plot the true vs. predicted values with improved styling\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot for the predicted values\n",
    "plt.scatter(true_y_testing, y_pred_testing_rf, alpha=0.7, label='Predicted RF', color='blue', edgecolors='w')\n",
    "\n",
    "# Scatter plot for the true values\n",
    "plt.scatter(true_y_testing, true_y_testing, alpha=0.7, label='True', color='red', edgecolors='w')\n",
    "\n",
    "# Diagonal line indicating perfect predictions\n",
    "plt.plot([true_y_testing.min(), true_y_testing.max()], [true_y_testing.min(), true_y_testing.max()], 'k--', lw=2, label='Perfect Prediction')\n",
    "\n",
    "# Styling the plot\n",
    "plt.style.use('ggplot')\n",
    "plt.xlabel('True Weight Lifted (Kg)', fontsize=14)\n",
    "plt.ylabel('Predicted Weight Lifted (Kg)', fontsize=14)\n",
    "plt.title('Random Forest LOO True vs. Predicted Weight Lifted (Testing Data)', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Save the predictions and the plot to files\n",
    "df_testing.to_csv('Testing_Set_Predictions_RF_LOO.csv', index=False)\n",
    "plt.savefig('True_vs_Predicted_Plot_RF_LOO.png', format='png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
